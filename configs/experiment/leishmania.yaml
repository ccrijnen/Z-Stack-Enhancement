# @package _global_

# to execute this experiment run:
# python scripts/train.py experiment=leishmania_generalization

defaults:
  - override /datamodule: leishmania_data.yaml
#  - override /model: adain_unet_2d.yaml
#  - override /model: adain_2d.yaml
  - override /model: unet_2d.yaml
  - override /callbacks: adain_callbacks.yaml
  - override /logger: tensorboard.yaml
  - override /trainer: ddp.yaml


trainer:
#  gpus: 2
  max_epochs: 100

datamodule:
  batch_size: 8
  num_workers: 32
#  num_workers: 0
  imsize: 512
#  scale: 0.75

model:
  net:
    in_channels: 3
    out_channels: 3
    style_loss_fn: "gram"
  lr: 1e-4
#  weight_decay: 1e-5
#  lr_decay: 0.99
  style_weight: 1e6

seed: 42
#name: leishmania_generalization/unet/${model.net.style_loss_fn}_loss/lr:${model.lr}-style_weight:${model.style_weight}-weight_decay:${model.weight_decay}-lr_decay:${model.lr_decay}
#name: leishmania_generalization/adain/${model.net.style_loss_fn}_loss/lr:${model.lr}-style_weight:${model.style_weight}-weight_decay:${model.weight_decay}-lr_decay:${model.lr_decay}
name: leishmania_generalization/u17/${model.net.style_loss_fn}_loss/lr:${model.lr}-style_weight:${model.style_weight}-weight_decay:${model.weight_decay}-lr_decay:${model.lr_decay}
