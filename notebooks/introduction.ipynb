{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as functional\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import save_image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from zse.datamodules.components.brain_datasets import ZStackDataset3D\n",
    "from zse.models.adain_module import AdaINLitModule2D\n",
    "from zse.models.components.adain_unet import AdaINUNet\n",
    "from zse.style_transfer.style_transfer import style_transfer\n",
    "from zse.utils.data_utils import read_h5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def save_nib(data, path, fname):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    if not os.path.exists(f\"{path}/{fname}.nii\"):\n",
    "        nib_image = nib.Nifti1Image(data.mul(255).byte().squeeze().permute(1, 2, 0).numpy(), np.identity(4))\n",
    "        nib.nifti1.save(nib_image, f\"{path}/{fname}.nii\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def make_border(img, size, color):\n",
    "    top, bottom, left, right = [size]*4\n",
    "    img_with_border = cv2.copyMakeBorder(np.stack([img, img, img], axis=2), top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    return img_with_border"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def plot(img, title, path=None, **border_kwargs):\n",
    "    if not len(border_kwargs) == 0:\n",
    "        img = img.mul(255).byte()\n",
    "    img = img.squeeze().detach().cpu().numpy()\n",
    "    if not len(border_kwargs) == 0:\n",
    "        img = make_border(img, **border_kwargs)\n",
    "    if path is not None:\n",
    "        if not len(border_kwargs) == 0:\n",
    "            plt.imsave(path, img)\n",
    "        else:\n",
    "            plt.imsave(path, img, vmin=0, vmax=1, cmap=\"gray\")\n",
    "    else:\n",
    "        plt.figure(dpi=100)\n",
    "        plt.title(title)\n",
    "        plt.imshow(img, vmin=0, vmax=1, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "home = \"/p/fastdata/bigbrains/personal/crijnen1\"\n",
    "data_root = f\"{home}/data\"\n",
    "zse_path = f\"..\"\n",
    "model_path = f\"{zse_path}/models/brain/adain_unet_3d\"\n",
    "dest = f\"{zse_path}/reports/introduction\"\n",
    "torch.hub.set_dir(f\"{home}/models\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "vgg19 = models.vgg19(pretrained=True)\n",
    "norm = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "adain_unet = AdaINUNet(vgg19, norm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Z-Stack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "z = 29\n",
    "data_test = ZStackDataset3D(f\"{data_root}/bigbrain_1micron/{z}/test/blurry/*.hdf5\", transform=transforms.ToTensor())\n",
    "loader = DataLoader(data_test, batch_size=1, num_workers=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, batch in enumerate(loader):\n",
    "    fname = batch[\"path\"][0].split(\"/\")[-1][:-5]\n",
    "    # save_nib(content, dest, fname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "fname = \"B21_0228_y25225_x17625\"\n",
    "to_tensor = transforms.ToTensor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "z = 29\n",
    "path = f\"{data_root}/bigbrain_1micron/{z}/test/blurry/{fname}.hdf5\"\n",
    "content = to_tensor(read_h5(path))[:,:128,:128].unsqueeze(1)\n",
    "style = content[[14]].expand(z, -1, -1, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "blurry = content.squeeze()\n",
    "plot(blurry[0], \"xy_bot\", f\"{dest}/brain/{fname}_xy_bot.png\")\n",
    "plot(blurry[14], \"xy_mid\", f\"{dest}/brain/{fname}_xy_mid.png\")\n",
    "plot(blurry[28], \"xy_top\", f\"{dest}/brain/{fname}_xy_top.png\")\n",
    "plot(blurry[14], \"s15\", f\"{dest}/brain/{fname}_s15.png\", size=3, color=[0,0,255]) # Blue\n",
    "plot(blurry[19], \"s20\", f\"{dest}/brain/{fname}_s20.png\", size=3, color=[0,255,255])\n",
    "plot(blurry[24], \"s25\", f\"{dest}/brain/{fname}_s25.png\", size=3, color=[255,255,0])\n",
    "plot(blurry[:, :, 63], \"xz\", f\"{dest}/brain/{fname}_xz.png\", size=1, color=[85,255,0]) # Green\n",
    "plot(blurry[:, 63, :], \"yz\", f\"{dest}/brain/{fname}_yz.png\", size=1, color=[255,0,0]) # Red"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "sharp = style.squeeze()\n",
    "pad_xz = torch.nn.ReflectionPad2d((0, 0, 14, 14))\n",
    "pad_yz = torch.nn.ReflectionPad2d((z//2, z//2, 0, 0))\n",
    "style_xz = pad_xz(sharp)\n",
    "style_yz = pad_yz(sharp)\n",
    "plot(style_xz[14, 0:29], \"xz_bot\", f\"{dest}/brain/{fname}_xz_bot.png\")\n",
    "plot(style_xz[14, 63-14:63+15], \"xz_mid\", f\"{dest}/brain/{fname}_xz_mid.png\")\n",
    "plot(style_xz[14, -30:-1], \"xz_top\", f\"{dest}/brain/{fname}_xz_top.png\")\n",
    "plot(style_yz[14, :, 0:29], \"xz_bot\", f\"{dest}/brain/{fname}_yz_bot.png\")\n",
    "plot(style_yz[14, :, 63-14:63+15], \"xz_mid\", f\"{dest}/brain/{fname}_yz_mid.png\")\n",
    "plot(style_yz[14, :, -30:-1], \"xz_top\", f\"{dest}/brain/{fname}_yz_top.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "ckpt_path = f\"{model_path}/gram/lr:0.001-beta:1000000.0_best.ckpt\"\n",
    "module = AdaINLitModule2D.load_from_checkpoint(ckpt_path, net=adain_unet, strict=False).to(device)\n",
    "module.freeze()\n",
    "module.eval()\n",
    "out = module({\"content\": content.to(device), \"style\": style.to(device)}).squeeze().cpu()\n",
    "module.cpu();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "plot(out[0], \"xy_bot\", f\"{dest}/brain/{fname}_out_xy_bot.png\")\n",
    "plot(out[14], \"xy_mid\", f\"{dest}/brain/{fname}_out_xy_mid.png\")\n",
    "plot(out[-1], \"xy_top\", f\"{dest}/brain/{fname}_out_xy_top.png\")\n",
    "plot(out[:, 0], \"xz_bot\", f\"{dest}/brain/{fname}_out_xz_bot.png\")\n",
    "plot(out[:, 63], \"xz_mid\", f\"{dest}/brain/{fname}_out_xz_mid.png\")\n",
    "plot(out[:, -1], \"xz_top\", f\"{dest}/brain/{fname}_out_xz_top.png\")\n",
    "plot(out[:, :, 0].T, \"yz_bot\", f\"{dest}/brain/{fname}_out_yz_bot.png\")\n",
    "plot(out[:, :, 63].T, \"yz_mid\", f\"{dest}/brain/{fname}_out_yz_mid.png\")\n",
    "plot(out[:, :, -1].T, \"yz_top\", f\"{dest}/brain/{fname}_out_yz_top.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "z = 20\n",
    "path = f\"{data_root}/bigbrain_1micron/{z}/test/blurry/{fname}.hdf5\"\n",
    "content = to_tensor(read_h5(path))[:,:128,:128].unsqueeze(1)\n",
    "style = content[[14]].expand(z, -1, -1, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "blurry = content.squeeze()\n",
    "plot(blurry[0], \"xy_bot\", f\"{dest}/brain/{fname}_{z}_bot.png\")\n",
    "plot(blurry[9], \"xy_mid\", f\"{dest}/brain/{fname}_{z}_mid.png\")\n",
    "plot(blurry[19], \"xy_top\", f\"{dest}/brain/{fname}_{z}_top.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "ckpt_path = f\"{model_path}/gram/lr:0.001-beta:1000000.0_best.ckpt\"\n",
    "module = AdaINLitModule2D.load_from_checkpoint(ckpt_path, net=adain_unet, strict=False).to(device)\n",
    "module.freeze()\n",
    "module.eval()\n",
    "out = module({\"content\": content.to(device), \"style\": style.to(device)}).squeeze().cpu()\n",
    "module.cpu();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "plot(out[0], \"xy_bot\", f\"{dest}/brain/{fname}_{z}_out_bot.png\")\n",
    "plot(out[9], \"xy_mid\", f\"{dest}/brain/{fname}_{z}_out_mid.png\")\n",
    "plot(out[19], \"xy_top\", f\"{dest}/brain/{fname}_{z}_out_top.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Style Transfer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def test_transform(size, crop):\n",
    "    transform_list = []\n",
    "    if size != 0:\n",
    "        transform_list.append(transforms.Resize(size))\n",
    "    if crop:\n",
    "        transform_list.append(transforms.CenterCrop(size))\n",
    "    transform_list.append(transforms.ToTensor())\n",
    "    transform = transforms.Compose(transform_list)\n",
    "    return transform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "content_imgs = [\"brad_pitt.jpg\", \"avril.jpg\", \"cornell.jpg\", \"chicago.jpg\"]\n",
    "style_imgs = [\"sketch.png\", \"asheville.jpg\", \"la_muse.jpg\", \"mondrian_cropped.jpg\"]\n",
    "trans = test_transform(512, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "for c, s in zip(content_imgs, style_imgs):\n",
    "    c_path = f\"{zse_path}/data/images/content/{c}\"\n",
    "    s_path = f\"{zse_path}/data/images/style/{s}\"\n",
    "    content = trans(Image.open(str(c_path))).unsqueeze(0)\n",
    "    style = trans(Image.open(str(s_path))).unsqueeze(0)\n",
    "    out = style_transfer(vgg19.features, content, style, content_layers=['relu4_2'], content_weights=1., style_weights=1e7,\n",
    "                         normalization=norm, optimizer=optim.LBFGS, loss_fn=functional.l1_loss, device=device)\n",
    "    output_name = f\"{dest}/style_transfer/{c[:-4]}_stylized_{s[:-4]}.jpg\"\n",
    "    save_image(out, output_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}